# Foundational Flower Detector Configuration
# This configuration implements the architectural decisions from project documentation
# Optimized for Intel Core Ultra 7 CPU training with Google Drive data integration

# Project metadata
project:
  name: "foundational_flower_detector"
  version: "1.0.0"
  description: "High-precision flower detection with hard negative mining"
  phase: "foundational"
  author: "Foundational Flower Detector Team"
  created_date: "2025-09-09"

# Data configuration - Google Drive integration
data:
  # Google Drive paths (primary data source)
  google_drive_base_path: "G:\\My Drive\\Floral_Detector\\Phase1_Foundational-Detector\\Phase1_Data"
  raw_data_path: "G:\\My Drive\\Floral_Detector\\Phase1_Foundational-Detector\\Phase1_Data\\raw_data"
  processed_data_path: "G:\\My Drive\\Floral_Detector\\Phase1_Foundational-Detector\\Phase1_Data\\processed_data"
  reports_path: "G:\\My Drive\\Floral_Detector\\Phase1_Foundational-Detector\\Phase1_Data\\reports"
  
  # Local paths (for working copies and outputs)
  local_data_path: "./data"
  local_raw_path: "./data/raw"
  local_processed_path: "./data/processed"
  
  # Dataset specifications
  positive_images_subpath: "positive_images"
  negative_images_subpath: "negative_images (1)"  # Updated to match actual Google Drive folder name
  annotations_subpath: "annotations"
  metadata_subpath: "metadata"
  
  # Dataset splits (deterministic)
  train_split: 0.7
  val_split: 0.2
  test_split: 0.1
  
  # Reproducibility (Decision A3 from architecture)
  global_random_seed: 42
  
  # Image specifications
  image_extensions: [".jpg", ".jpeg", ".png", ".bmp"]
  min_image_size: [224, 224]
  max_image_size: [1024, 1024]
  target_input_size: [224, 224]  # CPU-optimized smaller input
  
  # Dataset size management
  max_dataset_size:
    positive: 1000
    negative: 2000
    validation_positive: 200
    validation_negative: 400

# CPU-optimized training configuration for Intel Core Ultra 7
training:
  # Batch configuration (optimized for 32GB RAM)
  batch_size: 2                    # Small batch for CPU training
  validation_batch_size: 1
  gradient_accumulation_steps: 8   # Simulate larger batch
  
  # Learning parameters (conservative for stability)
  learning_rate: 0.001
  weight_decay: 0.0001
  momentum: 0.9
  gradient_clipping: 1.0
  
  # Training duration
  epochs: 50                       # More epochs with smaller batches
  patience: 10                     # Early stopping patience
  min_epochs: 10                   # Minimum training duration
  
  # CPU optimization (Intel Core Ultra 7: 16 logical cores)
  num_workers: 8                   # Half logical cores for data loading
  prefetch_factor: 2
  pin_memory: false                # No GPU benefit
  persistent_workers: true
  drop_last: true                  # Ensure consistent batch sizes
  
  # Optimizer configuration
  optimizer: "adam"
  scheduler: "plateau"
  scheduler_patience: 5
  scheduler_factor: 0.5
  min_lr: 0.000001
  
  # Mixed precision and compilation (CPU settings)
  mixed_precision: false           # Not beneficial for CPU
  compile_model: false             # Can be slower on CPU
  
  # Checkpointing and logging
  checkpoint_frequency: 5
  save_best_only: true
  save_last: true
  monitor_metric: "val_precision"
  monitor_mode: "max"
  
  # Validation frequency
  validation_frequency: 1          # Every epoch
  log_frequency: 100              # Every N steps

# Mask R-CNN model configuration (following He et al. 2017)
model:
  architecture: "mask_rcnn"
  backbone: "resnet50"             # Smaller backbone for CPU efficiency
  pretrained: true
  pretrained_weights: "coco"       # COCO pre-trained weights
  
  # Class configuration
  num_classes: 2                   # background + flower
  class_names: ["background", "flower"]
  class_weights: [1.0, 2.0]       # Higher weight for flower class
  
  # Input configuration (CPU-optimized)
  input_size: [224, 224]          # Smaller input for CPU training
  input_channels: 3
  input_pixel_mean: [123.675, 116.28, 103.53]   # ImageNet normalization
  input_pixel_std: [58.395, 57.12, 57.375]
  
  # RPN (Region Proposal Network) configuration
  rpn_anchor_scales: [32, 64, 128, 256, 512]
  rpn_anchor_ratios: [0.5, 1.0, 2.0]
  rpn_train_pre_nms_topN: 2000
  rpn_train_post_nms_topN: 1000
  rpn_test_pre_nms_topN: 1000
  rpn_test_post_nms_topN: 1000
  rpn_nms_threshold: 0.7
  
  # ROI configuration
  roi_pool_size: 7
  mask_pool_size: 14
  roi_positive_ratio: 0.25
  roi_batch_size: 512
  roi_positive_overlap: 0.5
  roi_negative_overlap_high: 0.5
  roi_negative_overlap_low: 0.1
  
  # FPN (Feature Pyramid Network) configuration
  fpn_num_filters: 256
  fpn_num_layers: 4

# Hard negative mining configuration (core innovation)
hard_negative_mining:
  # Detection thresholds (high precision focus)
  confidence_threshold: 0.90      # High threshold for hard negatives
  iou_threshold: 0.3
  nms_threshold: 0.5
  
  # Mining parameters
  max_false_positives_per_image: 5
  background_scan_batch_size: 10
  min_hard_negatives_per_cycle: 50
  max_cycles: 10
  cycle_exit_threshold: 50        # <50 new FPs = convergence
  
  # File management (atomic operations - Decision A1)
  verification_queue_file: "verification_queue.json"
  confirmed_negatives_log: "confirmed_hard_negatives.log"
  mining_log_file: "hard_negative_mining.log"
  
  # Background image scanning
  background_scan_limit: 50000    # Max images per scan cycle
  parallel_scanning: true
  scan_batch_workers: 4

# Evaluation configuration (scientific rigor)
evaluation:
  # Success thresholds (from architecture documents)
  precision_threshold: 0.98       # Primary success metric
  recall_threshold: 0.85          # Secondary success metric
  f1_threshold: 0.91             # Derived threshold
  
  # Evaluation parameters
  iou_threshold: 0.5              # COCO standard
  confidence_threshold: 0.5
  max_detections: 100
  
  # Challenge set (Decision A2)
  challenge_set_size: 100
  challenge_set_file: "challenge_set.json"
  challenge_evaluation_frequency: 5  # Every 5 epochs
  
  # Metrics logging
  detailed_metrics: true
  save_predictions: true
  save_confusion_matrix: true

# Hardware configuration (Intel Core Ultra 7 optimization)
hardware:
  # CPU specifications
  cpu_cores_logical: 16           # Intel Core Ultra 7
  cpu_cores_physical: 8
  memory_gb: 32
  cpu_architecture: "intel_ultra_7"
  
  # Threading configuration
  intraop_threads: 8              # TensorFlow intra-op parallelism
  interop_threads: 4              # TensorFlow inter-op parallelism
  mkl_threads: 8                  # Intel MKL threads
  
  # Optimizations
  use_multiprocessing: true
  enable_mkl: true                # Intel MKL optimization
  mkl_dnn: true                   # Intel oneDNN
  memory_growth: true             # TensorFlow memory management
  
  # System monitoring
  monitor_system: true
  memory_limit_gb: 28             # Leave 4GB for system
  cpu_usage_threshold: 0.95

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"
  
  # File logging
  log_file: "logs/training.log"
  max_file_size: "100MB"
  backup_count: 5
  encoding: "utf-8"
  
  # Console logging
  console_level: "INFO"
  console_format: "%(levelname)s - %(message)s"
  
  # TensorBoard
  tensorboard_dir: "logs/tensorboard"
  tensorboard_update_freq: 100
  tensorboard_write_graph: true
  tensorboard_write_images: true
  
  # MLflow (optional for experiment tracking)
  mlflow_enabled: false
  mlflow_tracking_uri: ""
  mlflow_experiment_name: "foundational_flower_detector"

# Paths configuration
paths:
  # Project directories
  project_root: "."
  source_dir: "./src"
  tests_dir: "./tests"
  
  # Data directories (local)
  data_dir: "./data"
  raw_data_dir: "./data/raw"
  processed_data_dir: "./data/processed"
  external_data_dir: "./data/external"
  
  # Output directories
  models_dir: "./models"
  checkpoints_dir: "./models/checkpoints"
  logs_dir: "./logs"
  reports_dir: "./reports"
  figures_dir: "./reports/figures"
  
  # Temporary directories
  temp_dir: "./tmp"
  cache_dir: "./cache"

# Streamlit UI configuration
ui:
  # Server settings
  port: 8501
  host: "localhost"
  debug: false
  
  # UI settings
  title: "Foundational Flower Detector - Verification UI"
  page_icon: "ðŸŒ¸"
  layout: "wide"
  initial_sidebar_state: "expanded"
  
  # Display settings
  images_per_page: 10
  max_image_display_size: [800, 600]
  thumbnail_size: [200, 200]
  
  # Interaction settings
  queue_refresh_interval: 30      # seconds
  auto_advance: true
  keyboard_shortcuts: true
  
  # Progress tracking
  show_progress: true
  show_statistics: true
  save_session_log: true

# Development and debugging configuration
development:
  debug: false
  verbose: true
  profile: false
  reproducible: true
  
  # Testing
  test_data_size: 100
  mock_training: false
  fast_dev_run: false
  
  # Development tools
  auto_reload: true
  jupyter_support: true
  notebook_dir: "./notebooks"
  
  # Code quality
  enable_linting: true
  enable_type_checking: true
  strict_mode: true
